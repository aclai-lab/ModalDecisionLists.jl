Main:

    Generic:
        ☐ Eliminare implementazione superflua cn2
            ✔ arrivare a due implementazioni uguali @done(24-04-03 11:05)
                ✔ sole_cn2 as orange_cn2(simple selector version) @done(24-03-14 20:39)
                ✔ base_cn2 as orange_cn2(simple selector version) @done(24-03-16 12:00)
            ☐ Testing
    
        ☐ new section in docu
        ☐ MLJ interface for cn2
        ✔ Aggiornare confronto tra LmCF @done(24-03-04 19:36)
        # (rimuovere confronto tramite Base.:(==))
        ☐ Laplace
        ☐ entropyMDL
        ☐ Rule validation
        ☐ LRS
        ☐ Weighted relative accuracy
    
    Utility:
        ✔ Implementing instances(PropositionalLogiset) @done(24-03-04 17:11)
            ✔ Gestione errore in istanziazione PropositionalLogiset{DataFrame}(SubDataFrame) @done(24-03-04 17:11)
            # già scritta soluzione temporanea
        ✔ add alphabet parameter @done(24-04-03 11:06)
        
    
    Testing:
        ☐ Scrivere test che chiama CN2, e che valuta la qualità del risultato
        ✔ Verificare 100% accuratezza sul dataset di trainig ? @done(24-03-01 03:02)
        ☐ Divisione train/test come nei test di ModalDecisionTrees.jl, (vedi iris)
        ☐ Time (@time) 
        ☐ Aggiungi qualche test (su un altro file test dedicato, per pulizia) che per verificare la robustezza di sole_cn2 e sequential_covering;
    
    Future: 
        ✔ Differenziare caso attributi discreti/categoriali
        ☐ Aggiungere campo supporting_labels (vettore)
        # Vettore delle labels delle istanze su cui la regola è costruita (ovvero, quelle che non sono coperte dalle regole precedenti), e nel 
        # info del constant model ci metti un campo supp_labels con le labels delle istanze che, tra queste, sono coperte dalla regola. 
        ☐ Aggiungere campo predicted_labels (forse)
        # labels predette dal modello, ma in principio le support_labels sono sufficienti 
        # per calcolare diverse metriche 
    