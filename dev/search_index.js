var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = ModalDecisionLists","category":"page"},{"location":"#ModalDecisionLists","page":"Home","title":"ModalDecisionLists","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Welcome to the documentation for ModalDecisionLists.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [ModalDecisionLists, ModalDecisionLists.MLJInterface, ModalDecisionLists.experimentals]","category":"page"},{"location":"#TODO-continue-this-example","page":"Home","title":"TODO continue this example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"sequentialcovering\nSearchMethod\nAtomSearch\nBeamSearch\nRandSearch","category":"page"},{"location":"#ModalDecisionLists.sequentialcovering","page":"Home","title":"ModalDecisionLists.sequentialcovering","text":"function sequentialcovering(\n    X::AbstractLogiset,\n    y::AbstractVector{<:CLabel},\n    w::Union{Nothing,AbstractVector{U},Symbol} = default_weights(length(y));\n    kwargs...\n)::DecisionList where {U<:Real}\n\nLearn a decision list on an logiset X with labels y and weights w following the classic sequential covering learning scheme. This involves iteratively learning a single rule, and removing the newly covered instances.\n\nKeyword Arguments\n\nsearchmethod::SearchMethod: The search method for finding single rules (see SearchMethod);\nloss_function::Function = soleentropy is the function that assigns a score to each partial solution.\nmax_infogain_ratio::Real=1.0: constrains the maximum information gain for anantecedent with respect to the uncovered training set. Its value is bounded between 0 and 1.\ndefault_alphabet::Union{Nothing,AbstractAlphabet}=nothing offers the flexibility to define a tailored alphabet upon which antecedents generation occurs.\ndiscretizedomain::Bool=false:  discretizes continuous variables by identifying optimal cut points\nsignificance_alpha::Union{Real,Nothing}=0.0 is the significant alpha\nmin_rule_coverage::Union{Nothing,Integer} = 1 specifies the minimum number of instances covered by each rule.\nmax_rule_length::Union{Nothing,Integer} = nothing specifies the maximum length allowed for a rule in the search algorithm.\nmax_rulebase_length::Union{Nothing,Integer} is the maximum length of the rulebase;\nsuppress_parity_warning::Bool if true, suppresses parity warnings.\nAny additional keyword argument will be imputed to the searchmethod, replacing its original value.\n\nExamples\n\n\njulia> X = PropositionalLogiset(iris_dataframe);\n\njulia> y = Vector{CLabel}(iris_labels);\n\njulia> sequentialcovering(X, y)\n▣\n├[1/22]┐(:sepal_length ≤ 4.8)\n│└ setosa\n├[2/22]┐(:sepal_length ≥ 7.1)\n│└ virginica\n├[3/22]┐(:sepal_length ≥ 7.0)\n│└ versicolor\n├[4/22]┐(:sepal_width ≤ 2.0)\n│└ versicolor\n├[5/22]┐(:sepal_width ≥ 3.5)\n│└ setosa\n├[6/22]┐(:petal_length ≤ 1.7)\n│└ setosa\n├[7/22]┐(:petal_length ≤ 4.4)\n│└ versicolor\n├[8/22]┐(:sepal_length ≤ 4.9)\n│└ virginica\n├[9/22]┐(:sepal_length ≤ 5.4)\n│└ versicolor\n├[10/22]┐(:petal_length ≤ 4.7)\n│└ versicolor\n├[11/22]┐(:sepal_length ≤ 5.8)\n│└ virginica\n├[12/22]┐(:sepal_width ≤ 2.2)\n│└ virginica\n├[13/22]┐(:sepal_width ≥ 3.3)\n│└ virginica\n├[14/22]┐(:petal_length ≥ 5.2)\n│└ virginica\n├[15/22]┐(:petal_width ≤ 1.4)\n│└ versicolor\n├[16/22]┐(:petal_width ≥ 1.9)\n│└ virginica\n├[17/22]┐(:sepal_length ≥ 6.7)\n│└ versicolor\n├[18/22]┐(:sepal_width ≤ 2.5)\n│└ versicolor\n├[19/22]┐(:sepal_length ≥ 6.1)\n│└ virginica\n├[20/22]┐(:sepal_width ≤ 2.7)\n│└ versicolor\n├[21/22]┐(:sepal_length ≥ 6.0)\n│└ virginica\n├[22/22]┐(:sepal_width ≤ 3.0)\n│└ virginica\n└✘ versicolor\n\nSee also SearchMethod, BeamSearch, PropositionalLogiset, DecisionList.\n\n\n\n\n\n","category":"function"},{"location":"#ModalDecisionLists.SearchMethod","page":"Home","title":"ModalDecisionLists.SearchMethod","text":"    SearchMethod\n\nAbstract type for all search methods to be used in sequentialcovering.\n\nAny search method implements a findbestantecedent method.\n\nSee also findbestantecedent, BeamSearch, RandSearch.\n\n\n\n\n\n","category":"type"},{"location":"#ModalDecisionLists.AtomSearch","page":"Home","title":"ModalDecisionLists.AtomSearch","text":"    AtomSearch\n\nMethod for conjunctions search to be used with BeamSearch, where the conjunctions are restricted to atomic conditions. This approach precisely implements the CN2 algorithm.\n\n\n\n\n\n","category":"type"},{"location":"#ModalDecisionLists.BeamSearch","page":"Home","title":"ModalDecisionLists.BeamSearch","text":"Search method to be used in sequentialcovering that explores the solution space selectively, maintaining a restricted set of partial solutions (the \"beam\") at each step.\n\nThe beam is dynamically updated to include the most promising solutions, allowing for efficient exploration of the solution space without examining all possibilities.\n\nKeyword Arguments\n\nconjuncts_search_method::SearchMethod=AtomSearch(): Defines the heuristic method by which possible conjuncts are generated during the beam search.\nbeam_width::Integer=3 is the width of the beam, i.e., the maximum number of partial solutions to maintain during the search.\n\nSee also sequentialcovering, SearchMethod, AtomSearch, RandSearch, specializeantecedents.\n\n\n\n\n\n","category":"type"},{"location":"#ModalDecisionLists.RandSearch","page":"Home","title":"ModalDecisionLists.RandSearch","text":"RandSearch (`SoleLogics.randformula`)\n\nSearch method to be used in sequentialcovering that explores the solutions space employing stochastic sampling strategies.\n\nKeyword Arguments\n\ncardinality::Integer=25: Defines the number of formulas generated during the search for a single rule. A higher cardinality increases the probability of finding an antecedent that better fits the data.\noperators::AbstractVector=[NEGATION, CONJUNCTION, DISJUNCTION]: Represents the set of logical operators used in the generation of formulas.\nsyntaxheight::Integer=2: Defines the maximum height of the syntactic tree representing a generated formula.\nrng::AbstractRNG=Random.GLOBAL_RNG: Specifies the random number generator to be used in the generation of formulas. By default, it uses the global random number generator.\natompicking_mode::Symbol=:uniform: Determines the probability distribution of MetaConditions when generating formulas. It can impose a :uniform distribution over the MetaConditions or a :weighted distribution based on the length of the thresholding values of each MetaCondition.\nsubalphabets_weights::Union{AbstractWeights,AbstractVector{<:Real},Nothing}=nothing: Allows biasing the probability distribution of each MetaCondition through a vector of real weights between 0 and 1.\n\nSee also sequentialcovering, SearchMethod, BeamSearch, specializeantecedents.\n\n\n\n\n\n","category":"type"}]
}
